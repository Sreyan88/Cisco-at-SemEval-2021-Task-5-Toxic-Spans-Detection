{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"tsd_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>Another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>Damn, a whole family. Sad indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>What a knucklehead. How can anyone not know th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \n",
       "0  Another violent and aggressive immigrant killi...  \n",
       "1  I am 56 years old, I am not your fucking junio...  \n",
       "2                  Damn, a whole family. Sad indeed.  \n",
       "3  What a knucklehead. How can anyone not know th...  \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = []\n",
    "\n",
    "for i, row in train.iterrows():\n",
    "    to_append_list = [int(x) for x in str(train[\"spans\"].iloc[i])[1:len(train[\"spans\"].iloc[i])-1].split(\", \") if len(x) > 0]\n",
    "    spans.append(to_append_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import more_itertools as mit\n",
    "span_grouped = []\n",
    "\n",
    "for i in range(len(spans)):\n",
    "    span_grouped.append([list(group) for group in mit.consecutive_groups(spans[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "\n",
    "for i in range(len(span_grouped)):\n",
    "    span_grouped_just_group_sentence = []\n",
    "    for ranges in span_grouped[i]:\n",
    "        span_grouped_just_group_groups = []\n",
    "        if len(ranges) > 0:\n",
    "            span_grouped_just_group_groups = [ranges[0],ranges[-1]]\n",
    "        \n",
    "        span_grouped_just_group_sentence.append(span_grouped_just_group_groups)\n",
    "        \n",
    "    final.append(span_grouped_just_group_sentence)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer = []\n",
    "\n",
    "for text,spans in zip(texts,final):\n",
    "    span_word = []\n",
    "    sentence = text.split(\" \")\n",
    "    for span in spans:\n",
    "        span_word_span = []\n",
    "        length_covered = -1\n",
    "        i=0\n",
    "        while length_covered < span[0]:\n",
    "            length_covered += len(sentence[i]) +1\n",
    "            i+=1\n",
    "        span_word_span.append(i-1)\n",
    "        \n",
    "        while length_covered < span[1]:\n",
    "            length_covered += len(sentence[i]) +1\n",
    "            i+=1\n",
    "        span_word_span.append(i-1)\n",
    "        \n",
    "        span_word.append(span_word_span)\n",
    "    \n",
    "    final_answer.append(span_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "  \n",
    "# Function checks if the string \n",
    "# contains any special character \n",
    "def run(string):\n",
    "    regex = re.compile('[@_!#$%^&*()<>?/\\|}{~:]')    \n",
    "    if(regex.search(string) == None): \n",
    "        return False \n",
    "          \n",
    "    else: \n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "def get_me_index(original,to_find,range_to_find,count_spaces,dict_of_texts,dict_of_texts_2,flag):\n",
    "    #print(\"lolwa\")\n",
    "    #if flag:\n",
    "    #    print(original)\n",
    "    length = len(original)\n",
    "    if range_to_find[0] == 0:\n",
    "        original_broken = \" \".join(original)[range_to_find[0]:].split(\" \")\n",
    "    elif range_to_find[0] > len(to_find):\n",
    "        if (range_to_find[0] - len(to_find) - count_spaces) >= 0:\n",
    "            original_broken = \" \".join(original)[range_to_find[0] - len(to_find) - count_spaces:].split(\" \")\n",
    "        else:\n",
    "            original_broken = \" \".join(original)[0:].split(\" \")\n",
    "    else:\n",
    "        original_broken = \" \".join(original)[range_to_find[0] - 1:].split(\" \")\n",
    "\n",
    "    for i in range(len(original_broken)):\n",
    "        if to_find in original_broken[i]:\n",
    "            index_final = i\n",
    "            #new change\n",
    "            break\n",
    "            \n",
    "    leave_it = len(original) - len(original_broken)\n",
    "    count_words = 0\n",
    "\n",
    "    for i in range(leave_it,len(original)):\n",
    "        if (to_find in original[i]) and (to_find in original_broken[index_final]) :\n",
    "            count_words += 1\n",
    "            return i, dict_of_texts, dict_of_texts_2\n",
    "            \n",
    "def get_discovery(span,group,count_spaces):\n",
    "    \n",
    "    combined_sentence = \" \".join(span)\n",
    "    \n",
    "    if group[0] > 0:\n",
    "        if (group[0]-1-count_spaces) >= 0:\n",
    "            waste_part = combined_sentence[0:group[0]-1-count_spaces]\n",
    "        else:\n",
    "            waste_part = combined_sentence[0:group[0]-1]\n",
    "    else:\n",
    "        waste_part = combined_sentence[0:0]\n",
    "\n",
    "                \n",
    "    return len(waste_part.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentences = []\n",
    "targets = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    \n",
    "    flag = False\n",
    "    \n",
    "    if i==199:\n",
    "        flag = True\n",
    "        \n",
    "    x = texts[i]\n",
    "    \n",
    "    x_modified = re.sub(' +', ' ',\" \".join(text.replace(\"\\n\",\" \") for text in x.split(\" \")))\n",
    "    \n",
    "    split_x = x_modified.split(\" \")\n",
    "        \n",
    "    count_spaces = len(x) - len(x_modified)\n",
    "\n",
    "    \n",
    "    y = [\"O\" for i in range(len(split_x))]\n",
    "    grouped_y = final[i]\n",
    "    \n",
    "    dict_of_texts = {}\n",
    "    \n",
    "    dict_of_texts_2 = {}\n",
    "    \n",
    "    for group in grouped_y:\n",
    "        \n",
    "        span = x[group[0]:group[1]+1]\n",
    "        \n",
    "        split_span = span.split(\" \")\n",
    "                \n",
    "        split_span = re.sub(' +', ' ',\" \".join(text.replace(\"\\n\",\" \") for text in split_span)).split(\" \")\n",
    "        \n",
    "        for item in split_span:\n",
    "            if item in dict_of_texts:\n",
    "                dict_of_texts[item] += 1\n",
    "            else:\n",
    "                dict_of_texts[item] = 1\n",
    "                \n",
    "            dict_of_texts_2[item] = 0\n",
    "            \n",
    "    \n",
    "    for group in grouped_y:\n",
    "\n",
    "        span = x[group[0]:group[1]+1]\n",
    "        \n",
    "        split_span = span.split(\" \")\n",
    "        \n",
    "        split_span = re.sub(' +', ' ',\" \".join(text.replace(\"\\n\",\" \") for text in split_span)).split(\" \")\n",
    "            \n",
    "        discovered = 0\n",
    " \n",
    "        if len(split_span) > 1:\n",
    "            \n",
    "            if len(split_span) > 2:\n",
    "                \n",
    "                for j in range(len(split_span)):\n",
    "                    if j == 0:\n",
    "                        if split_span[j] in split_x[get_discovery(split_x,group,count_spaces) + discovered -1:]:\n",
    "                            \n",
    "                            y[split_x.index(split_span[j],get_discovery(split_x,group,count_spaces) + discovered -1)] = \"B\"\n",
    "\n",
    "                            #new\n",
    "                            dict_of_texts[split_span[j]] -= 1\n",
    "                            dict_of_texts_2[split_span[j]] += 1\n",
    "                            \n",
    "                        else:\n",
    "                            index,dict_of_texts,dict_of_texts_2 = get_me_index(split_x,split_span[j],group,count_spaces,dict_of_texts,dict_of_texts_2,flag)\n",
    "                            y[index] = \"B\"\n",
    "                            \n",
    "                    elif j == (len(split_span) - 1):\n",
    "                        if flag:\n",
    "                            print(group)\n",
    "                        if split_span[j] in split_x[get_discovery(split_x,group,count_spaces) + discovered -1:]: \n",
    "                            y[split_x.index(split_span[j],get_discovery(split_x,group,count_spaces) + discovered -1)] = \"L\"\n",
    "                            #new\n",
    "                            dict_of_texts[split_span[j]] -= 1\n",
    "                            dict_of_texts_2[split_span[j]] += 1\n",
    "                        else:\n",
    "                            index,dict_of_texts,dict_of_texts_2 = get_me_index(split_x,split_span[j],group,count_spaces,dict_of_texts,dict_of_texts_2,flag)\n",
    "                            y[index] = \"L\"\n",
    "                    else:\n",
    "                        if split_span[j] in split_x[get_discovery(split_x,group,count_spaces) + discovered -1:]:\n",
    "                            y[split_x.index(split_span[j],get_discovery(split_x,group,count_spaces) + discovered -1)] = \"I\"\n",
    "                            #new\n",
    "                            dict_of_texts[split_span[j]] -= 1\n",
    "                            dict_of_texts_2[split_span[j]] += 1\n",
    "                            \n",
    "                        else:\n",
    "                            index,dict_of_texts,dict_of_texts_2 = get_me_index(split_x,split_span[j],group,count_spaces,dict_of_texts,dict_of_texts_2,flag)\n",
    "                            y[index] = \"I\"\n",
    "                        \n",
    "                    discovered += 1\n",
    "                        \n",
    "            elif len(split_span) == 2:\n",
    "                \n",
    "                \n",
    "                if split_span[0] in split_x[get_discovery(split_x,group,count_spaces) + discovered -1:]:\n",
    "                    y[split_x.index(split_span[0],get_discovery(split_x,group,count_spaces) + discovered -1)] = \"B\"\n",
    "                    #new\n",
    "                    dict_of_texts[split_span[0]] -= 1\n",
    "                    dict_of_texts_2[split_span[0]] += 1\n",
    "                else:\n",
    "                    index,dict_of_texts,dict_of_texts_2 = get_me_index(split_x,split_span[0],group,count_spaces,dict_of_texts,dict_of_texts_2,flag)\n",
    "                    y[index] = \"B\"\n",
    "                #new change   \n",
    "                discovered += 1\n",
    "\n",
    "                if split_span[1] in split_x[get_discovery(split_x,group,count_spaces) + discovered -1:]:\n",
    "                    if flag:\n",
    "                        print(\"Hola\")\n",
    "                        print(split_x[get_discovery(split_x,group,count_spaces) + discovered -1:])\n",
    "                    y[split_x.index(split_span[1],get_discovery(split_x,group,count_spaces) + discovered -1)] = \"L\"\n",
    "                    #new\n",
    "                    dict_of_texts[split_span[1]] -= 1\n",
    "                    dict_of_texts_2[split_span[1]] += 1\n",
    "                else:\n",
    "                    if flag:\n",
    "                        print(\"lol\")\n",
    "                    index,dict_of_texts,dict_of_texts_2 = get_me_index(split_x,split_span[1],group,count_spaces,dict_of_texts,dict_of_texts_2,flag)\n",
    "                    y[index] = \"L\"\n",
    "                #new change  \n",
    "                discovered += 1\n",
    "                \n",
    "                \n",
    "        elif len(split_span) == 1:\n",
    "            \n",
    "            if split_span[0] in split_x[get_discovery(split_x,group,count_spaces) + discovered -1:]:\n",
    "                #if flag:\n",
    "                #    print(\"lol\")\n",
    "                y[split_x.index(split_span[0],get_discovery(split_x,group,count_spaces) + discovered -1)] = \"U\"\n",
    "                #new\n",
    "                dict_of_texts[split_span[0]] -= 1\n",
    "                dict_of_texts_2[split_span[0]] += 1\n",
    "            else:\n",
    "                index,dict_of_texts,dict_of_texts_2 = get_me_index(split_x,split_span[0],group,count_spaces,dict_of_texts,dict_of_texts_2,flag)\n",
    "                y[index] = \"U\"\n",
    "            #new change   \n",
    "            discovered += 1\n",
    "        \n",
    "\n",
    "            \n",
    "    targets.append(y)\n",
    "    sentences.append(split_x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "loli = []\n",
    "loli2 = []\n",
    "l = 6971\n",
    "for i in range(len(sentences[l])):\n",
    "    new_first = re.findall(r\"[\\w]+|[\\\"\\'*.,!?;]\", sentences[l][i])\n",
    "    \n",
    "    if (len(new_first) == 3) and (\"'\" in new_first):\n",
    "        if (new_first[1] == \"'\"):\n",
    "            new_first = [new_first[0],new_first[1] + new_first[2]]\n",
    "        \n",
    "    loli.extend(new_first)\n",
    "    \n",
    "    if targets[l][i] == \"I\":\n",
    "        loli2.extend([\"I\"] * len(new_first))\n",
    "    elif (targets[l][i] == \"L\") :\n",
    "        to_append = [\"O\"] * len(new_first)\n",
    "        to_append[0] = \"L\"\n",
    "        loli2.extend(to_append)\n",
    "    elif (targets[l][i] == \"B\"):\n",
    "        to_append = [\"I\"] * len(new_first)\n",
    "        if (len(new_first) > 1) and ((new_first[0] == \"'\") or (new_first[0] == '\"')):\n",
    "            to_append[0] = \"O\"\n",
    "            to_append[1] = \"B\"\n",
    "        else:\n",
    "            to_append[0] = \"B\"\n",
    "        loli2.extend(to_append)\n",
    "    elif (targets[l][i] == \"U\"):\n",
    "        if len(new_first) == 1:\n",
    "            loli2.extend(\"U\")\n",
    "        else:\n",
    "            if \"-\" in new_first :\n",
    "                to_append = [\"I\"] * len(new_first)\n",
    "                to_append[0] = \"B\"\n",
    "                to_append[-1] = \"L\"\n",
    "                loli2.extend(to_append)\n",
    "            elif new_first.count(\"'\") == 2 and (new_first[1] != \"'\"):\n",
    "                to_append = [\"O\"] * len(new_first)\n",
    "                to_append[1] = \"U\"\n",
    "                loli2.extend(to_append)\n",
    "            else:\n",
    "                to_append = [\"O\"] * len(new_first)\n",
    "                to_append[0] = \"U\"\n",
    "                loli2.extend(to_append)\n",
    "    else:\n",
    "        loli2.extend([\"O\"] * len(new_first))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,j in zip(loli,loli2):\n",
    "#    print(i + \"\\t\" + j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_final_sentence = []\n",
    "answer_final_span = []\n",
    "\n",
    "for l in range(0,len(sentences)):\n",
    "    if l == 4499:\n",
    "        continue\n",
    "    loli = []\n",
    "    loli2 = []\n",
    "    \n",
    "    for i in range(len(sentences[l])):\n",
    "        new_first = re.findall(r\"[\\w]+|[\\\"\\'*.,!?;]\", sentences[l][i])\n",
    "\n",
    "        if (len(new_first) == 3) and (\"'\" in new_first):\n",
    "            if (new_first[1] == \"'\"):\n",
    "                new_first = [new_first[0],new_first[1] + new_first[2]]\n",
    "\n",
    "        loli.extend(new_first)\n",
    "\n",
    "        if targets[l][i] == \"I\":\n",
    "            loli2.extend([\"I\"] * len(new_first))\n",
    "        elif (targets[l][i] == \"L\") :\n",
    "            to_append = [\"O\"] * len(new_first)\n",
    "            to_append[0] = \"L\"\n",
    "            loli2.extend(to_append)\n",
    "        elif (targets[l][i] == \"B\"):\n",
    "            to_append = [\"I\"] * len(new_first)\n",
    "            if (len(new_first) > 1) and ((new_first[0] == \"'\") or (new_first[0] == '\"')):\n",
    "                to_append[0] = \"O\"\n",
    "                to_append[1] = \"B\"\n",
    "            else:\n",
    "                to_append[0] = \"B\"\n",
    "            loli2.extend(to_append)\n",
    "        elif (targets[l][i] == \"U\"):\n",
    "            if len(new_first) == 1:\n",
    "                loli2.extend(\"U\")\n",
    "            else:\n",
    "                if \"-\" in new_first :\n",
    "                    to_append = [\"I\"] * len(new_first)\n",
    "                    to_append[0] = \"B\"\n",
    "                    to_append[-1] = \"L\"\n",
    "                    loli2.extend(to_append)\n",
    "                elif (new_first.count(\"'\") == 2) and (new_first[1] != \"'\"):\n",
    "                    to_append = [\"O\"] * len(new_first)\n",
    "                    to_append[1] = \"U\"\n",
    "                    loli2.extend(to_append)\n",
    "                else:\n",
    "                    to_append = [\"O\"] * len(new_first)\n",
    "                    to_append[0] = \"U\"\n",
    "                    loli2.extend(to_append)\n",
    "        else:\n",
    "            loli2.extend([\"O\"] * len(new_first))\n",
    "            \n",
    "    for f in range(len(loli2)):\n",
    "        if (loli2[f] == \"B\") or (loli2[f] == \"L\") or (loli2[f] == \"U\"):\n",
    "            loli2[f] = \"I\"\n",
    "            \n",
    "    answer_final_sentence.append(loli)\n",
    "    answer_final_span.append(loli2)\n",
    "    \n",
    "    \n",
    "with open(\"train_flair_IO.txt\",'w',encoding = \"utf-8\") as f:\n",
    "    \n",
    "    for g in range(len(answer_final_sentence)):\n",
    "        for word,tag in zip(answer_final_sentence[g],answer_final_span[g]):\n",
    "            f.write(word+'\\t'+tag+'\\n')\n",
    "                \n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
