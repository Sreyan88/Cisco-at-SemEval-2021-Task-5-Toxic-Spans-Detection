{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"tsd_trial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[6939:].reset_index()\n",
    "train.drop('index',axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of list with character offsets of dataset\n",
    "\n",
    "spans = []\n",
    "\n",
    "for i, row in train.iterrows():\n",
    "    to_append_list = [int(x) for x in str(train[\"spans\"].iloc[i])[1:len(train[\"spans\"].iloc[i])-1].split(\", \") if len(x) > 0]\n",
    "    spans.append(to_append_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group non-contiguous spans\n",
    "\n",
    "import more_itertools as mit\n",
    "span_grouped = []\n",
    "\n",
    "for i in range(len(spans)):\n",
    "    span_grouped.append([list(group) for group in mit.consecutive_groups(spans[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find starting and ending offset of non-contiguos offset\n",
    "\n",
    "final = []\n",
    "\n",
    "for i in range(len(span_grouped)):\n",
    "    span_grouped_just_group_sentence = []\n",
    "    for ranges in span_grouped[i]:\n",
    "        span_grouped_just_group_groups = []\n",
    "        #print(ranges)\n",
    "        if len(ranges) > 0:\n",
    "            span_grouped_just_group_groups = [ranges[0],ranges[-1]]\n",
    "        \n",
    "        span_grouped_just_group_sentence.append(span_grouped_just_group_groups)\n",
    "        \n",
    "    final.append(span_grouped_just_group_sentence)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ground Truth\n",
    "\n",
    "with open('gold.txt', 'w',encoding=\"utf-8\") as f:\n",
    "    for i in range(len(final)):\n",
    "        for span in final[i]:\n",
    "            if len(final[i]):\n",
    "                #print(final[i])\n",
    "                f.write(f\"{i}\\t{span[0]}\\t{span[1]}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Prediction\n",
    "\n",
    "with open(\"dev/bert_io_dev.txt\", 'r') as file1:\n",
    "    lines = file1.readlines()\n",
    "\n",
    "answer_token = []\n",
    "answers_token = []\n",
    "\n",
    "answer_pred = []\n",
    "answers_pred = []\n",
    "\n",
    "for line in lines:\n",
    "    if not (line.isspace()):\n",
    "        feats = line.strip().split()\n",
    "        answer_token.append(feats[0])\n",
    "        answer_pred.append(feats[1])\n",
    "        \n",
    "    else:\n",
    "        answers_token.append(answer_token)\n",
    "        answers_pred.append(answer_pred)\n",
    "        answer_token= []\n",
    "        answer_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for changing scheme from IO --> BILOU\n",
    "\n",
    "def change_scheme_IO_BILOU(input_list):\n",
    "    if len(input_list) == 0:\n",
    "        return input_list\n",
    "    elif len(input_list) == 1:\n",
    "        if input_list[0] == \"I\":\n",
    "            input_list[0] = \"U\"\n",
    "        else:\n",
    "            return input_list\n",
    "\n",
    "    for i in range(len(input_list)):\n",
    "        if (input_list[i] == \"I\") and (i != 0) and (i != (len(input_list)-1)) :\n",
    "            if (input_list[i-1] == \"O\") and (input_list[i+1] == \"O\"):\n",
    "                input_list[i] = \"U\"\n",
    "            elif input_list[i-1] == \"O\":\n",
    "                input_list[i] = \"B\"\n",
    "            elif input_list[i+1] == \"O\":\n",
    "                input_list[i] = \"L\"\n",
    "        elif input_list[i] == \"I\" and (i == 0):\n",
    "            if input_list[i+1] == \"O\":\n",
    "                input_list[i] = \"U\"\n",
    "            elif input_list[i+1] == \"I\":\n",
    "                input_list[i] = \"B\"\n",
    "        elif input_list[i] == \"I\" and (i == (len(input_list) - 1)):\n",
    "            if input_list[i-1] == \"O\":\n",
    "                input_list[i] = \"U\"\n",
    "            elif (input_list[i-1] == \"I\") or (input_list[i-1] == \"B\"):\n",
    "                input_list[i] = \"L\"\n",
    "                \n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for changing scheme from BIO --> BILOU\n",
    "\n",
    "def change_scheme_BIO_BILOU(input_list):\n",
    "    if len(input_list) == 0:\n",
    "        return input_list\n",
    "    elif len(input_list) == 1:\n",
    "        if input_list[0] == \"B\":\n",
    "            input_list[0] = \"U\"\n",
    "        else:\n",
    "            return input_list\n",
    "\n",
    "    for i in range(len(input_list)):\n",
    "        if (input_list[i] == \"I\") and (i != 0) and (i != (len(input_list)-1)) :\n",
    "            if input_list[i+1] == \"O\":\n",
    "                input_list[i] = \"L\"\n",
    "                \n",
    "        elif input_list[i] == \"I\" and (i == (len(input_list) - 1)):\n",
    "            if (input_list[i-1] == \"I\") or (input_list[i-1] == \"B\"):\n",
    "                input_list[i] = \"L\"\n",
    "                \n",
    "        elif (input_list[i] == \"B\") and (i != 0) and (i != (len(input_list)-1)) :\n",
    "            if (input_list[i-1] == \"O\") and (input_list[i+1] == \"O\"):\n",
    "                input_list[i] = \"U\"\n",
    "            elif (input_list[i-1] == \"I\") or (input_list[i-1] == \"B\"):\n",
    "                input_list[i] = \"L\"\n",
    "            \n",
    "                \n",
    "        elif input_list[i] == \"B\" and (i == 0):\n",
    "            if input_list[i+1] == \"O\":\n",
    "                input_list[i] = \"U\"\n",
    "        \n",
    "        elif input_list[i] == \"B\" and (i == (len(input_list) - 1)):\n",
    "            if (input_list[i-1] == \"O\"):\n",
    "                input_list[i] = \"U\"\n",
    "            elif (input_list[i-1] == \"I\") or (input_list[i-1] == \"B\"):\n",
    "                input_list[i] = \"L\"\n",
    "                \n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "\n",
    "for i in range(len(answers_pred)):\n",
    "    answers_pred[i] = change_scheme_IO_BILOU(answers_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get starting offset in case of B\n",
    "\n",
    "def get_start(sentence,index,to_find):\n",
    "    \n",
    "    flag = False\n",
    "    \n",
    "    split_sentence = sentence.split(\" \")\n",
    "    \n",
    "    m = 0\n",
    "    n = 0\n",
    "    \n",
    "    while m < len(split_sentence):\n",
    "        #print(m)\n",
    "        if to_find in split_sentence[m]:\n",
    "\n",
    "            n = 0\n",
    "            while n < len(sentence):\n",
    "        \n",
    "                start = m\n",
    "                #print(sentence)\n",
    "                #print(n)\n",
    "                #print(split_sentence[start])\n",
    "                #print(sentence.find(split_sentence[start],n))\n",
    "                actual_start = sentence.find(split_sentence[start],n)\n",
    "                \n",
    "                while sentence[actual_start:actual_start + len(to_find)] != to_find:\n",
    "                    actual_start += 1\n",
    "                \n",
    "                if sentence[actual_start] == \"'\":\n",
    "                    flag = True\n",
    "\n",
    "                \n",
    "                sentence_corrected = re.sub(' +', ' ',\" \".join(text.replace(\"\\n\",\" \") for text in sentence[:actual_start].split(\" \")))\n",
    "                split_sentence_corrected = sentence_corrected.split(\" \")\n",
    "                new_sentence = []\n",
    "                for item in split_sentence_corrected:\n",
    "                    new_first = re.findall(r\"[\\w]+|[\\\"\\'*.,!?;]\", item)\n",
    "                    if (len(new_first) == 3) and (\"'\" in new_first):\n",
    "                        if (new_first[1] == \"'\"):\n",
    "                            new_first = [new_first[0],new_first[1] + new_first[2]]\n",
    "                    new_sentence.extend(new_first)\n",
    "                #print(new_sentence)\n",
    "                    \n",
    "                if len(new_sentence) == index:\n",
    "                    return actual_start\n",
    "                if flag and (len(new_sentence) == index - 1) :\n",
    "                    actual_start += 1\n",
    "                    return actual_start\n",
    "                    \n",
    "                \n",
    "                n += 1\n",
    "                \n",
    "        m += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "# Function to get starting offset in case of L\n",
    "\n",
    "def get_end(sentence,index,to_find):\n",
    "    \n",
    "    flag = False\n",
    "    \n",
    "    split_sentence = sentence.split(\" \")\n",
    "    \n",
    "    m = 0\n",
    "    n = 0\n",
    "    \n",
    "    while m < len(split_sentence):\n",
    "        #print(m)\n",
    "        if to_find in split_sentence[m]:\n",
    "\n",
    "            n = 0\n",
    "            while n < len(sentence):\n",
    "        \n",
    "                start = m\n",
    "                #print(sentence)\n",
    "                #print(n)\n",
    "                #print(split_sentence[start])\n",
    "                #print(sentence.find(split_sentence[start],n))\n",
    "                actual_start = sentence.find(split_sentence[start],n)\n",
    "                \n",
    "                while sentence[actual_start:actual_start + len(to_find)] != to_find:\n",
    "                    actual_start += 1\n",
    "                \n",
    "\n",
    "                \n",
    "                sentence_corrected = re.sub(' +', ' ',\" \".join(text.replace(\"\\n\",\" \") for text in sentence[:actual_start].split(\" \")))\n",
    "                split_sentence_corrected = sentence_corrected.split(\" \")\n",
    "                new_sentence = []\n",
    "                for item in split_sentence_corrected:\n",
    "                    new_first = re.findall(r\"[\\w]+|[\\\"\\'*.,!?;]\", item)\n",
    "                    if (len(new_first) == 3) and (\"'\" in new_first):\n",
    "                        if (new_first[1] == \"'\"):\n",
    "                            new_first = [new_first[0],new_first[1] + new_first[2]]\n",
    "                    new_sentence.extend(new_first)\n",
    "                    \n",
    "                    \n",
    "                if len(new_sentence) == index:\n",
    "                    actual_start += len(to_find) - 1\n",
    "                    if (sentence[actual_start:actual_start + 2] == \"'s\") or (sentence[actual_start:actual_start + 2] == \"'t\"):\n",
    "                        actual_start += 2\n",
    "                        \n",
    "                    return actual_start\n",
    "                \n",
    "                n += 1\n",
    "                \n",
    "        m += 1\n",
    "        \n",
    "        #x = len(sentence) -1\n",
    "        #return x\n",
    "        \n",
    "\n",
    "# Function to get starting and endind offset in case of U\n",
    "        \n",
    "def get_start_end(sentence,index,to_find):\n",
    "    flag = False\n",
    "    \n",
    "    split_sentence = sentence.split(\" \")\n",
    "    \n",
    "    m = 0\n",
    "    n = 0\n",
    "    #print(\"Hola\")\n",
    "    while m < len(split_sentence):\n",
    "        #print(m)\n",
    "        if to_find in split_sentence[m]:\n",
    "\n",
    "            n = 0\n",
    "            while n < len(sentence):\n",
    "        \n",
    "                start = m\n",
    "                #print(sentence)\n",
    "                #print(n)\n",
    "                #print(split_sentence[start])\n",
    "                #print(sentence.find(split_sentence[start],n))\n",
    "                #print(sentence)\n",
    "                actual_start = sentence.find(split_sentence[start],n)\n",
    "                #print(actual_start)\n",
    "                while sentence[actual_start:actual_start + len(to_find)] != to_find:\n",
    "                    actual_start += 1\n",
    "                    \n",
    "                starting = actual_start\n",
    "                \n",
    "                if sentence[actual_start] == \"'\":\n",
    "                    flag = True\n",
    "                    \n",
    "                \n",
    "                sentence_corrected = re.sub(' +', ' ',\" \".join(text.replace(\"\\n\",\" \") for text in sentence[:actual_start].split(\" \")))\n",
    "                #print(sentence_corrected)\n",
    "                split_sentence_corrected = sentence_corrected.split(\" \")\n",
    "                new_sentence = []\n",
    "                for item in split_sentence_corrected:\n",
    "                    new_first = re.findall(r\"[\\w]+|[\\\"\\'*.,!?;]\", item)\n",
    "                    if (len(new_first) == 3) and (\"'\" in new_first):\n",
    "                        if (new_first[1] == \"'\"):\n",
    "                            new_first = [new_first[0],new_first[1] + new_first[2]]\n",
    "                    new_sentence.extend(new_first)\n",
    "                    #if flag:\n",
    "                #print(new_sentence)\n",
    "                    \n",
    "                    \n",
    "                #print(to_find)\n",
    "                #print(new_sentence)\n",
    "                #print(index)\n",
    "                if len(new_sentence) == index:\n",
    "                    #print(\"Hola\")\n",
    "                    actual_start += len(to_find) - 1\n",
    "                    #print(starting)\n",
    "                    #print(actual_start)\n",
    "                    if (sentence[actual_start:actual_start + 2] == \"'s\") or (sentence[actual_start:actual_start + 2] == \"'t\"):\n",
    "                        actual_start += 2\n",
    "                    return starting, actual_start\n",
    "                    \n",
    "                elif flag and (len(new_sentence) == index - 1):\n",
    "                    starting += 1\n",
    "                    actual_start += 1\n",
    "                    actual_start += len(to_find) - 1\n",
    "                    \n",
    "                    if (sentence[actual_start:actual_start + 2] == \"'s\") or (sentence[actual_start:actual_start + 2] == \"'t\"):\n",
    "                        actual_start += 2\n",
    "                        \n",
    "                    \n",
    "                        \n",
    "                    return starting, actual_start\n",
    "                \n",
    "                n += 1\n",
    "                \n",
    "        m += 1\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the above function to get starting and ending offsets\n",
    "\n",
    "import re\n",
    "\n",
    "all_predicted = []\n",
    "for j in range(len(answers_pred)):\n",
    "    i = 0\n",
    "    sentence_predicted_span = []\n",
    "    \n",
    "    if (j == 1693) :\n",
    "        all_predicted.append(sentence_predicted_span)\n",
    "        continue\n",
    "        \n",
    "    while i < len(answers_token[j]):\n",
    "        sentence_predicted_one_span = []\n",
    "        \n",
    "        if answers_pred[j][i] == \"B\":\n",
    "            start = get_start(train[\"text\"].iloc[j],i,answers_token[j][i])\n",
    "            while answers_pred[j][i] != \"L\":\n",
    "                i+=1\n",
    "            if answers_pred[j][i] == \"L\":\n",
    "                end = get_end(train[\"text\"].iloc[j],i,answers_token[j][i])\n",
    "                if end == None:\n",
    "                    end = len(train[\"text\"].iloc[j]) - 2\n",
    "            sentence_predicted_one_span.append(start)\n",
    "            sentence_predicted_one_span.append(end)\n",
    "            \n",
    "\n",
    "        elif answers_pred[j][i] == \"U\":            \n",
    "            start,end = get_start_end(train[\"text\"].iloc[j],i,answers_token[j][i])\n",
    "            sentence_predicted_one_span.append(start)\n",
    "            sentence_predicted_one_span.append(end)\n",
    "            \n",
    "        if len(sentence_predicted_one_span):\n",
    "            sentence_predicted_span.append(sentence_predicted_one_span)\n",
    "\n",
    "        i += 1\n",
    "    all_predicted.append(sentence_predicted_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand starting and ending offsets into list of offsets for submission\n",
    "\n",
    "for i in range(len(all_predicted)):\n",
    "    final_answer = []\n",
    "    for j in range(len(all_predicted[i])):\n",
    "        answer = [number for number in range(all_predicted[i][j][0],all_predicted[i][j][1] + 1)]\n",
    "        final_answer.extend(answer)\n",
    "    all_predicted[i] = final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write into a file\n",
    "\n",
    "with open(\"results/Dev/spans-pred-bert-io.txt\", \"w\") as out:\n",
    "    for uid, text_scores in enumerate(all_predicted):\n",
    "        out.write(f\"{str(uid)}\\t{str(text_scores)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
